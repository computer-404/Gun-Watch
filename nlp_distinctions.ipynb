{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "PREDICTING\n",
      "[[  74  172   33]\n",
      " [  79 3675   98]\n",
      " [  27   78  721]]\n",
      "0.9017550938067379\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "# Write an NLP algorithm that can classify if a tweet is hate speech or not\n",
    "# using the twitter dataset provided in the labeled_data.csv file\n",
    "# Use an SVC classifier\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('labeled_data.csv', encoding = 'latin-1')\n",
    "\n",
    "# Cleaning the texts\n",
    "dataset['tweet'] = dataset['tweet'].apply(lambda x: x.lower())\n",
    "dataset['tweet'] = dataset['tweet'].apply(lambda x: re.sub('[^a-zA-Z]', ' ', x))\n",
    "dataset['tweet'] = dataset['tweet'].apply(lambda x: x.split())\n",
    "ps = PorterStemmer()\n",
    "dataset['tweet'] = dataset['tweet'].apply(lambda x: [ps.stem(word) for word in x if not word in set(stopwords.words('english'))])\n",
    "dataset['tweet'] = dataset['tweet'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Creating the Bag of Words model\n",
    "cv = CountVectorizer(max_features = 1500)\n",
    "X = cv.fit_transform(dataset['tweet']).toarray()\n",
    "y = dataset['class']\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print('TRAINING')\n",
    "# Fitting SVC to the Training set\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print('PREDICTING')\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "\n",
    "# Predicting a new result\n",
    "new_tweet = 'I hate you'\n",
    "new_tweet = new_tweet.lower()\n",
    "new_tweet = re.sub('[^a-zA-Z]', ' ', new_tweet)\n",
    "new_tweet = new_tweet.split()\n",
    "new_tweet = [ps.stem(word) for word in new_tweet if not word in set(stopwords.words('english'))]\n",
    "new_tweet = ' '.join(new_tweet)\n",
    "new_tweet = cv.transform([new_tweet]).toarray()\n",
    "new_pred = classifier.predict(new_tweet)\n",
    "print(new_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to a pkl file\n",
    "import pickle\n",
    "\n",
    "with open('sentiment_model.pkl', 'wb') as file:\n",
    "    pickle.dump(classifier, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
